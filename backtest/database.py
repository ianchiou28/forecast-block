"""
Aè‚¡æ¿å—æ¶¨åœé¢„æµ‹ç³»ç»Ÿ - å›æµ‹æ•°æ®åº“æ¨¡å—
è®°å½•æ¯æ—¥é¢„æµ‹ç»“æœä¸å®é™…è¡¨ç°ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹å‡†ç¡®æ€§
"""
import sqlite3
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Tuple
import logging
from pathlib import Path
import json

from config.settings import DATA_DIR, DATABASE_CONFIG

logger = logging.getLogger(__name__)


class BacktestDatabase:
    """å›æµ‹æ•°æ®åº“ç®¡ç†"""
    
    def __init__(self):
        self.db_path = DATA_DIR / "backtest.db"
        self._init_database()
    
    def _init_database(self):
        """åˆå§‹åŒ–å›æµ‹æ•°æ®åº“è¡¨ç»“æ„"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æ¯æ—¥é¢„æµ‹è®°å½•è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS daily_predictions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                predict_date TEXT NOT NULL,          -- é¢„æµ‹æ—¥æœŸï¼ˆTæ—¥å‘å‡ºé¢„æµ‹ï¼‰
                target_date TEXT NOT NULL,           -- ç›®æ ‡æ—¥æœŸï¼ˆT+1æ—¥å®é™…éªŒè¯ï¼‰
                sector_id TEXT NOT NULL,
                sector_name TEXT NOT NULL,
                predict_rank INTEGER,                -- é¢„æµ‹æ’å
                predict_score REAL,                  -- é¢„æµ‹å¾—åˆ†
                predict_reason TEXT,                 -- é¢„æµ‹ç†ç”±
                -- å®é™…ç»“æœï¼ˆæ¬¡æ—¥æ”¶ç›˜åå¡«å……ï¼‰
                actual_change_pct REAL,              -- å®é™…æ¶¨è·Œå¹…
                actual_limit_up_count INTEGER,       -- å®é™…æ¶¨åœå®¶æ•°
                actual_rank INTEGER,                 -- å®é™…æ¶¨å¹…æ’å
                is_hit INTEGER DEFAULT 0,            -- æ˜¯å¦å‘½ä¸­ï¼ˆæ¶¨å¹…>3%æˆ–æœ‰æ¶¨åœï¼‰
                -- å…ƒæ•°æ®
                created_at TEXT,
                updated_at TEXT,
                UNIQUE(predict_date, sector_id)
            )
        """)
        
        # æ¯æ—¥æ±‡æ€»è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS daily_summary (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                predict_date TEXT UNIQUE NOT NULL,   -- é¢„æµ‹æ—¥æœŸ
                target_date TEXT,                    -- ç›®æ ‡æ—¥æœŸ
                -- é¢„æµ‹ç»Ÿè®¡
                total_predictions INTEGER,           -- é¢„æµ‹æ•°é‡
                -- å®é™…ç»“æœç»Ÿè®¡
                hit_count INTEGER DEFAULT 0,         -- å‘½ä¸­æ•°
                hit_rate REAL DEFAULT 0,             -- å‘½ä¸­ç‡
                avg_return REAL DEFAULT 0,           -- å¹³å‡æ”¶ç›Š
                max_return REAL DEFAULT 0,           -- æœ€å¤§æ”¶ç›Š
                min_return REAL DEFAULT 0,           -- æœ€å°æ”¶ç›Š
                total_limit_up INTEGER DEFAULT 0,    -- æ€»æ¶¨åœæ•°
                -- åŸºå‡†å¯¹æ¯”
                benchmark_return REAL DEFAULT 0,     -- åŸºå‡†æ”¶ç›Šï¼ˆå…¨å¸‚åœºå‡å€¼ï¼‰
                excess_return REAL DEFAULT 0,        -- è¶…é¢æ”¶ç›Š
                -- çŠ¶æ€
                status TEXT DEFAULT 'pending',       -- pending/validated
                created_at TEXT,
                validated_at TEXT
            )
        """)
        
        # ç´¯è®¡ç»©æ•ˆè¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS performance_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                metric_date TEXT UNIQUE NOT NULL,
                -- ç´¯è®¡æŒ‡æ ‡
                total_days INTEGER,                  -- æ€»äº¤æ˜“å¤©æ•°
                cumulative_return REAL,              -- ç´¯è®¡æ”¶ç›Šç‡
                cumulative_hit_rate REAL,            -- ç´¯è®¡å‘½ä¸­ç‡
                sharpe_ratio REAL,                   -- å¤æ™®æ¯”ç‡
                max_drawdown REAL,                   -- æœ€å¤§å›æ’¤
                win_rate REAL,                       -- èƒœç‡
                -- æ»šåŠ¨æŒ‡æ ‡
                rolling_7d_return REAL,              -- 7æ—¥æ»šåŠ¨æ”¶ç›Š
                rolling_30d_return REAL,             -- 30æ—¥æ»šåŠ¨æ”¶ç›Š
                rolling_7d_hit_rate REAL,            -- 7æ—¥å‘½ä¸­ç‡
                -- æ›´æ–°æ—¶é—´
                updated_at TEXT
            )
        """)
        
        # æ¨¡å‹ç‰ˆæœ¬è®°å½•è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS model_versions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                version_date TEXT NOT NULL,
                model_type TEXT,
                train_samples INTEGER,
                valid_ndcg REAL,
                features_used TEXT,                  -- JSONæ ¼å¼
                notes TEXT,
                created_at TEXT
            )
        """)
        
        conn.commit()
        conn.close()
        logger.info(f"å›æµ‹æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {self.db_path}")
    
    def record_predictions(self, predictions: pd.DataFrame, predict_date: str = None):
        """
        è®°å½•æ¯æ—¥é¢„æµ‹ç»“æœ
        
        Args:
            predictions: é¢„æµ‹ç»“æœDataFrame
            predict_date: é¢„æµ‹æ—¥æœŸï¼ˆé»˜è®¤ä»Šå¤©ï¼‰
        """
        if predictions.empty:
            logger.warning("é¢„æµ‹ç»“æœä¸ºç©ºï¼Œè·³è¿‡è®°å½•")
            return
        
        if predict_date is None:
            predict_date = datetime.now().strftime("%Y-%m-%d")
        
        # è®¡ç®—ç›®æ ‡æ—¥æœŸï¼ˆä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ï¼‰
        target_date = self._get_next_trading_day(predict_date)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # æ’å…¥é¢„æµ‹è®°å½•
        for _, row in predictions.iterrows():
            try:
                cursor.execute("""
                    INSERT OR REPLACE INTO daily_predictions 
                    (predict_date, target_date, sector_id, sector_name, 
                     predict_rank, predict_score, predict_reason, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    predict_date,
                    target_date,
                    row.get('sector_id', ''),
                    row.get('sector_name', ''),
                    row.get('rank', 0),
                    row.get('pred_score', 0),
                    row.get('prediction_reason', ''),
                    now,
                    now
                ))
            except Exception as e:
                logger.error(f"è®°å½•é¢„æµ‹å¤±è´¥: {e}")
        
        # åˆ›å»ºæ¯æ—¥æ±‡æ€»è®°å½•
        cursor.execute("""
            INSERT OR REPLACE INTO daily_summary 
            (predict_date, target_date, total_predictions, status, created_at)
            VALUES (?, ?, ?, 'pending', ?)
        """, (predict_date, target_date, len(predictions), now))
        
        conn.commit()
        conn.close()
        
        logger.info(f"å·²è®°å½• {len(predictions)} æ¡é¢„æµ‹åˆ°å›æµ‹æ•°æ®åº“")
    
    def validate_predictions(self, target_date: str, actual_data: pd.DataFrame):
        """
        éªŒè¯é¢„æµ‹ç»“æœï¼ˆç”¨å®é™…æ•°æ®æ›´æ–°ï¼‰
        
        Args:
            target_date: ç›®æ ‡æ—¥æœŸ
            actual_data: å®é™…æ•°æ®DataFrameï¼Œéœ€åŒ…å« sector_name, change_pct, limit_up_count
        """
        if actual_data.empty:
            logger.warning("å®é™…æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡éªŒè¯")
            return
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # è·å–è¯¥æ—¥æœŸçš„é¢„æµ‹è®°å½•
        cursor.execute("""
            SELECT id, sector_name FROM daily_predictions 
            WHERE target_date = ?
        """, (target_date,))
        predictions = cursor.fetchall()
        
        if not predictions:
            logger.warning(f"æœªæ‰¾åˆ° {target_date} çš„é¢„æµ‹è®°å½•")
            conn.close()
            return
        
        # è®¡ç®—å®é™…æ’å
        actual_data = actual_data.copy()
        actual_data['actual_rank'] = actual_data['change_pct'].rank(ascending=False)
        
        # æ›´æ–°æ¯æ¡é¢„æµ‹çš„å®é™…ç»“æœ
        hit_count = 0
        returns = []
        total_limit_up = 0
        
        for pred_id, sector_name in predictions:
            # æŸ¥æ‰¾å¯¹åº”çš„å®é™…æ•°æ®
            actual_row = actual_data[actual_data['sector_name'] == sector_name]
            
            if actual_row.empty:
                continue
            
            actual_change = actual_row['change_pct'].values[0]
            actual_limit_up = actual_row.get('limit_up_count', pd.Series([0])).values[0]
            actual_rank = actual_row['actual_rank'].values[0]
            
            # åˆ¤æ–­æ˜¯å¦å‘½ä¸­ï¼ˆæ¶¨å¹…>3% æˆ– æœ‰æ¶¨åœï¼‰
            is_hit = 1 if (actual_change > 3 or actual_limit_up > 0) else 0
            
            cursor.execute("""
                UPDATE daily_predictions 
                SET actual_change_pct = ?, actual_limit_up_count = ?, 
                    actual_rank = ?, is_hit = ?, updated_at = ?
                WHERE id = ?
            """, (actual_change, actual_limit_up, actual_rank, is_hit, now, pred_id))
            
            hit_count += is_hit
            returns.append(actual_change)
            total_limit_up += actual_limit_up
        
        # è®¡ç®—åŸºå‡†æ”¶ç›Šï¼ˆå…¨å¸‚åœºå¹³å‡ï¼‰
        benchmark_return = actual_data['change_pct'].mean()
        
        # æ›´æ–°æ¯æ—¥æ±‡æ€»
        avg_return = np.mean(returns) if returns else 0
        max_return = np.max(returns) if returns else 0
        min_return = np.min(returns) if returns else 0
        hit_rate = hit_count / len(predictions) if predictions else 0
        excess_return = avg_return - benchmark_return
        
        # æ‰¾åˆ°å¯¹åº”çš„predict_date
        cursor.execute("""
            SELECT predict_date FROM daily_predictions 
            WHERE target_date = ? LIMIT 1
        """, (target_date,))
        result = cursor.fetchone()
        predict_date = result[0] if result else None
        
        if predict_date:
            cursor.execute("""
                UPDATE daily_summary 
                SET hit_count = ?, hit_rate = ?, avg_return = ?, 
                    max_return = ?, min_return = ?, total_limit_up = ?,
                    benchmark_return = ?, excess_return = ?,
                    status = 'validated', validated_at = ?
                WHERE predict_date = ?
            """, (hit_count, hit_rate, avg_return, max_return, min_return,
                  total_limit_up, benchmark_return, excess_return, now, predict_date))
        
        conn.commit()
        conn.close()
        
        logger.info(f"å·²éªŒè¯ {target_date} é¢„æµ‹: å‘½ä¸­ç‡={hit_rate:.2%}, å¹³å‡æ”¶ç›Š={avg_return:.2f}%, è¶…é¢={excess_return:.2f}%")
    
    def auto_validate_yesterday(self, processor):
        """
        è‡ªåŠ¨éªŒè¯æ˜¨æ—¥é¢„æµ‹ï¼ˆä½¿ç”¨æœ€æ–°æ•°æ®ï¼‰
        
        Args:
            processor: SectorDataProcessorå®ä¾‹
        """
        # è·å–å¾…éªŒè¯çš„è®°å½•
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT DISTINCT target_date FROM daily_summary 
            WHERE status = 'pending' AND target_date <= date('now')
        """)
        pending_dates = [row[0] for row in cursor.fetchall()]
        conn.close()
        
        if not pending_dates:
            logger.info("æ²¡æœ‰å¾…éªŒè¯çš„é¢„æµ‹è®°å½•")
            return
        
        # åŠ è½½å®é™…æ•°æ®
        df = processor.load_history_data(days=30)
        
        for target_date in pending_dates:
            actual_data = df[df['date'] == target_date]
            if not actual_data.empty:
                self.validate_predictions(target_date, actual_data)
    
    def get_performance_report(self, days: int = 30) -> Dict:
        """
        è·å–ç»©æ•ˆæŠ¥å‘Š
        
        Args:
            days: ç»Ÿè®¡å¤©æ•°
            
        Returns:
            ç»©æ•ˆæŒ‡æ ‡å­—å…¸
        """
        conn = sqlite3.connect(self.db_path)
        
        # è·å–æ±‡æ€»æ•°æ®
        query = f"""
            SELECT * FROM daily_summary 
            WHERE status = 'validated'
            ORDER BY predict_date DESC
            LIMIT {days}
        """
        df_summary = pd.read_sql(query, conn)
        
        # è·å–è¯¦ç»†é¢„æµ‹æ•°æ®
        query_detail = f"""
            SELECT * FROM daily_predictions 
            WHERE actual_change_pct IS NOT NULL
            ORDER BY predict_date DESC
        """
        df_detail = pd.read_sql(query_detail, conn)
        conn.close()
        
        if df_summary.empty:
            return {"status": "no_data", "message": "æš‚æ— å·²éªŒè¯çš„é¢„æµ‹æ•°æ®"}
        
        # è®¡ç®—å„é¡¹æŒ‡æ ‡
        report = {
            "status": "success",
            "period": f"æœ€è¿‘{len(df_summary)}å¤©",
            "total_predictions": int(df_summary['total_predictions'].sum()),
            
            # å‘½ä¸­ç‡
            "overall_hit_rate": df_summary['hit_rate'].mean(),
            "total_hits": int(df_summary['hit_count'].sum()),
            
            # æ”¶ç›Šç»Ÿè®¡
            "avg_daily_return": df_summary['avg_return'].mean(),
            "total_return": df_summary['avg_return'].sum(),
            "max_single_return": df_summary['max_return'].max(),
            "min_single_return": df_summary['min_return'].min(),
            
            # è¶…é¢æ”¶ç›Š
            "avg_excess_return": df_summary['excess_return'].mean(),
            "total_excess_return": df_summary['excess_return'].sum(),
            
            # æ¶¨åœç»Ÿè®¡
            "total_limit_up_captured": int(df_summary['total_limit_up'].sum()),
            
            # æŒ‰æ’åç»Ÿè®¡
            "top1_hit_rate": self._calc_rank_hit_rate(df_detail, 1),
            "top3_hit_rate": self._calc_rank_hit_rate(df_detail, 3),
            "top5_hit_rate": self._calc_rank_hit_rate(df_detail, 5),
            
            # æœ€è¿‘è¡¨ç°
            "recent_7d_hit_rate": df_summary.head(7)['hit_rate'].mean() if len(df_summary) >= 7 else None,
            "recent_7d_return": df_summary.head(7)['avg_return'].mean() if len(df_summary) >= 7 else None,
        }
        
        return report
    
    def _calc_rank_hit_rate(self, df: pd.DataFrame, rank: int) -> float:
        """è®¡ç®—ç‰¹å®šæ’åçš„å‘½ä¸­ç‡"""
        rank_data = df[df['predict_rank'] <= rank]
        if rank_data.empty:
            return 0
        return rank_data['is_hit'].mean()
    
    def _get_next_trading_day(self, date_str: str) -> str:
        """è·å–ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ï¼ˆç®€å•å®ç°ï¼Œè·³è¿‡å‘¨æœ«ï¼‰"""
        date = datetime.strptime(date_str, "%Y-%m-%d")
        next_day = date + timedelta(days=1)
        
        # è·³è¿‡å‘¨æœ«
        while next_day.weekday() >= 5:  # 5=å‘¨å…­, 6=å‘¨æ—¥
            next_day += timedelta(days=1)
        
        return next_day.strftime("%Y-%m-%d")
    
    def get_prediction_history(self, days: int = 7) -> pd.DataFrame:
        """è·å–é¢„æµ‹å†å²è®°å½•"""
        conn = sqlite3.connect(self.db_path)
        query = f"""
            SELECT 
                p.predict_date,
                p.target_date,
                p.sector_name,
                p.predict_rank,
                p.predict_score,
                p.actual_change_pct,
                p.actual_limit_up_count,
                p.is_hit,
                s.hit_rate as daily_hit_rate,
                s.avg_return as daily_avg_return
            FROM daily_predictions p
            LEFT JOIN daily_summary s ON p.predict_date = s.predict_date
            ORDER BY p.predict_date DESC, p.predict_rank ASC
            LIMIT {days * 10}
        """
        df = pd.read_sql(query, conn)
        conn.close()
        return df
    
    def export_report(self, output_path: str = None) -> str:
        """å¯¼å‡ºå›æµ‹æŠ¥å‘Š"""
        if output_path is None:
            output_path = DATA_DIR / f"backtest_report_{datetime.now().strftime('%Y%m%d')}.md"
        
        report = self.get_performance_report(days=30)
        history = self.get_prediction_history(days=7)
        
        lines = [
            "# ğŸ“Š Aè‚¡æ¿å—æ¶¨åœé¢„æµ‹ç³»ç»Ÿ - å›æµ‹æŠ¥å‘Š",
            "",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "---",
            "",
            "## ğŸ“ˆ æ•´ä½“ç»©æ•ˆ",
            "",
            f"| æŒ‡æ ‡ | æ•°å€¼ |",
            f"|------|------|",
            f"| ç»Ÿè®¡å‘¨æœŸ | {report.get('period', 'N/A')} |",
            f"| æ€»é¢„æµ‹æ¬¡æ•° | {report.get('total_predictions', 0)} |",
            f"| æ€»å‘½ä¸­æ¬¡æ•° | {report.get('total_hits', 0)} |",
            f"| **æ•´ä½“å‘½ä¸­ç‡** | **{report.get('overall_hit_rate', 0):.2%}** |",
            f"| å¹³å‡æ—¥æ”¶ç›Š | {report.get('avg_daily_return', 0):.2f}% |",
            f"| ç´¯è®¡æ”¶ç›Š | {report.get('total_return', 0):.2f}% |",
            f"| **å¹³å‡è¶…é¢æ”¶ç›Š** | **{report.get('avg_excess_return', 0):.2f}%** |",
            f"| æ•è·æ¶¨åœæ•° | {report.get('total_limit_up_captured', 0)} |",
            "",
            "## ğŸ¯ åˆ†æ’åå‘½ä¸­ç‡",
            "",
            f"| æ’å | å‘½ä¸­ç‡ |",
            f"|------|--------|",
            f"| Top-1 | {report.get('top1_hit_rate', 0):.2%} |",
            f"| Top-3 | {report.get('top3_hit_rate', 0):.2%} |",
            f"| Top-5 | {report.get('top5_hit_rate', 0):.2%} |",
            "",
        ]
        
        if not history.empty:
            lines.extend([
                "## ğŸ“‹ è¿‘æœŸé¢„æµ‹è®°å½•",
                "",
                "| é¢„æµ‹æ—¥æœŸ | æ¿å— | æ’å | å®é™…æ¶¨å¹… | æ¶¨åœæ•° | å‘½ä¸­ |",
                "|----------|------|------|----------|--------|------|",
            ])
            
            for _, row in history.head(20).iterrows():
                hit_mark = "âœ…" if row['is_hit'] == 1 else "âŒ"
                change = f"{row['actual_change_pct']:.2f}%" if pd.notna(row['actual_change_pct']) else "å¾…éªŒè¯"
                limit_up = int(row['actual_limit_up_count']) if pd.notna(row['actual_limit_up_count']) else "-"
                lines.append(
                    f"| {row['predict_date']} | {row['sector_name']} | {int(row['predict_rank'])} | {change} | {limit_up} | {hit_mark} |"
                )
        
        lines.extend([
            "",
            "---",
            "",
            "*æŠ¥å‘Šç”± Aè‚¡æ¿å—æ¶¨åœé¢„æµ‹ç³»ç»Ÿ è‡ªåŠ¨ç”Ÿæˆ*",
        ])
        
        content = "\n".join(lines)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info(f"å›æµ‹æŠ¥å‘Šå·²å¯¼å‡º: {output_path}")
        return str(output_path)


class BacktestAnalyzer:
    """å›æµ‹åˆ†æå™¨"""
    
    def __init__(self, db: BacktestDatabase):
        self.db = db
    
    def analyze_by_sector(self) -> pd.DataFrame:
        """æŒ‰æ¿å—åˆ†æå‘½ä¸­ç‡"""
        conn = sqlite3.connect(self.db.db_path)
        query = """
            SELECT 
                sector_name,
                COUNT(*) as predict_count,
                SUM(is_hit) as hit_count,
                AVG(is_hit) as hit_rate,
                AVG(actual_change_pct) as avg_return,
                SUM(actual_limit_up_count) as total_limit_up
            FROM daily_predictions
            WHERE actual_change_pct IS NOT NULL
            GROUP BY sector_name
            HAVING predict_count >= 3
            ORDER BY hit_rate DESC
        """
        df = pd.read_sql(query, conn)
        conn.close()
        return df
    
    def analyze_by_weekday(self) -> pd.DataFrame:
        """æŒ‰æ˜ŸæœŸå‡ åˆ†æ"""
        conn = sqlite3.connect(self.db.db_path)
        query = """
            SELECT 
                strftime('%w', target_date) as weekday,
                COUNT(*) as predict_count,
                AVG(is_hit) as hit_rate,
                AVG(actual_change_pct) as avg_return
            FROM daily_predictions
            WHERE actual_change_pct IS NOT NULL
            GROUP BY weekday
            ORDER BY weekday
        """
        df = pd.read_sql(query, conn)
        conn.close()
        
        # è½¬æ¢æ˜ŸæœŸ
        weekday_map = {'0': 'å‘¨æ—¥', '1': 'å‘¨ä¸€', '2': 'å‘¨äºŒ', '3': 'å‘¨ä¸‰', 
                       '4': 'å‘¨å››', '5': 'å‘¨äº”', '6': 'å‘¨å…­'}
        df['weekday'] = df['weekday'].map(weekday_map)
        
        return df
    
    def get_best_performing_sectors(self, top_n: int = 10) -> pd.DataFrame:
        """è·å–è¡¨ç°æœ€å¥½çš„æ¿å—"""
        df = self.analyze_by_sector()
        return df.head(top_n)


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    # æµ‹è¯•å›æµ‹æ•°æ®åº“
    db = BacktestDatabase()
    
    # æ¨¡æ‹Ÿé¢„æµ‹æ•°æ®
    test_predictions = pd.DataFrame({
        "sector_id": ["BK0001", "BK0002", "BK0003"],
        "sector_name": ["AIæ™ºèƒ½ä½“", "AIGCæ¦‚å¿µ", "å†›æ°‘èåˆ"],
        "rank": [1, 2, 3],
        "pred_score": [0.95, 0.90, 0.85],
        "prediction_reason": ["èµ„é‡‘æµå…¥å¤§", "åŠ¨é‡å¼º", "åŒ—å‘å¢æŒ"]
    })
    
    # è®°å½•é¢„æµ‹
    db.record_predictions(test_predictions)
    
    # è·å–ç»©æ•ˆæŠ¥å‘Š
    report = db.get_performance_report()
    print("ç»©æ•ˆæŠ¥å‘Š:", report)
    
    # å¯¼å‡ºæŠ¥å‘Š
    db.export_report()
