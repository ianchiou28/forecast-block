"""
ETFé¢„æµ‹ç³»ç»Ÿ - ETFå›æµ‹æ•°æ®åº“æ¨¡å—
è®°å½•ETFé¢„æµ‹ç»“æœä¸å®é™…è¡¨ç°ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹å‡†ç¡®æ€§
"""
import sqlite3
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Tuple
import logging
from pathlib import Path
import json

from config.settings import DATA_DIR, REPORT_DIR

logger = logging.getLogger(__name__)


class ETFBacktestDatabase:
    """ETFå›æµ‹æ•°æ®åº“ç®¡ç†"""
    
    def __init__(self):
        self.db_path = DATA_DIR / "etf_backtest.db"
        self._init_database()
    
    def _init_database(self):
        """åˆå§‹åŒ–ETFå›æµ‹æ•°æ®åº“è¡¨ç»“æ„"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ETFæ¯æ—¥é¢„æµ‹è®°å½•è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS etf_daily_predictions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                predict_date TEXT NOT NULL,          -- é¢„æµ‹æ—¥æœŸï¼ˆTæ—¥å‘å‡ºé¢„æµ‹ï¼‰
                target_date TEXT NOT NULL,           -- ç›®æ ‡æ—¥æœŸï¼ˆT+1æ—¥å®é™…éªŒè¯ï¼‰
                etf_code TEXT NOT NULL,
                etf_name TEXT NOT NULL,
                predict_rank INTEGER,                -- é¢„æµ‹æ’å
                predict_score REAL,                  -- é¢„æµ‹å¾—åˆ†
                predict_reason TEXT,                 -- é¢„æµ‹ç†ç”±
                -- å®é™…ç»“æœï¼ˆæ¬¡æ—¥æ”¶ç›˜åå¡«å……ï¼‰
                actual_change_pct REAL,              -- å®é™…æ¶¨è·Œå¹…
                actual_rank INTEGER,                 -- å®é™…æ¶¨å¹…æ’å
                is_hit INTEGER DEFAULT 0,            -- æ˜¯å¦å‘½ä¸­ï¼ˆæ¶¨å¹…>0ï¼‰
                is_top5 INTEGER DEFAULT 0,           -- æ˜¯å¦åœ¨å®é™…Top5
                -- å…ƒæ•°æ®
                created_at TEXT,
                updated_at TEXT,
                UNIQUE(predict_date, etf_code)
            )
        """)
        
        # ETFæ¯æ—¥æ±‡æ€»è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS etf_daily_summary (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                predict_date TEXT UNIQUE NOT NULL,   -- é¢„æµ‹æ—¥æœŸ
                target_date TEXT,                    -- ç›®æ ‡æ—¥æœŸ
                -- é¢„æµ‹ç»Ÿè®¡
                total_predictions INTEGER,           -- é¢„æµ‹æ•°é‡
                -- å®é™…ç»“æœç»Ÿè®¡
                hit_count INTEGER DEFAULT 0,         -- å‘½ä¸­æ•°ï¼ˆæ¶¨å¹…>0ï¼‰
                hit_rate REAL DEFAULT 0,             -- å‘½ä¸­ç‡
                top5_hit_count INTEGER DEFAULT 0,    -- Top5å‘½ä¸­æ•°
                top5_hit_rate REAL DEFAULT 0,        -- Top5å‘½ä¸­ç‡
                avg_return REAL DEFAULT 0,           -- å¹³å‡æ”¶ç›Š
                max_return REAL DEFAULT 0,           -- æœ€å¤§æ”¶ç›Š
                min_return REAL DEFAULT 0,           -- æœ€å°æ”¶ç›Š
                -- åŸºå‡†å¯¹æ¯”
                benchmark_return REAL DEFAULT 0,     -- åŸºå‡†æ”¶ç›Šï¼ˆETFæ± å‡å€¼ï¼‰
                excess_return REAL DEFAULT 0,        -- è¶…é¢æ”¶ç›Š
                -- çŠ¶æ€
                status TEXT DEFAULT 'pending',       -- pending/validated
                created_at TEXT,
                validated_at TEXT
            )
        """)
        
        # ETFç´¯è®¡ç»©æ•ˆè¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS etf_performance_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                metric_date TEXT UNIQUE NOT NULL,
                -- ç´¯è®¡æŒ‡æ ‡
                total_days INTEGER,                  -- æ€»äº¤æ˜“å¤©æ•°
                cumulative_return REAL,              -- ç´¯è®¡æ”¶ç›Šç‡
                cumulative_hit_rate REAL,            -- ç´¯è®¡å‘½ä¸­ç‡
                sharpe_ratio REAL,                   -- å¤æ™®æ¯”ç‡
                max_drawdown REAL,                   -- æœ€å¤§å›æ’¤
                win_rate REAL,                       -- èƒœç‡
                -- æ»šåŠ¨æŒ‡æ ‡
                rolling_7d_return REAL,              -- 7æ—¥æ»šåŠ¨æ”¶ç›Š
                rolling_30d_return REAL,             -- 30æ—¥æ»šåŠ¨æ”¶ç›Š
                rolling_7d_hit_rate REAL,            -- 7æ—¥å‘½ä¸­ç‡
                -- æ›´æ–°æ—¶é—´
                updated_at TEXT
            )
        """)
        
        # ETFæ¨¡å‹ç‰ˆæœ¬è®°å½•è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS etf_model_versions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                version_date TEXT NOT NULL,
                model_type TEXT,
                train_samples INTEGER,
                valid_ndcg REAL,
                valid_mse REAL,
                train_start TEXT,
                train_end TEXT,
                features_used TEXT,                  -- JSONæ ¼å¼
                params TEXT,                         -- JSONæ ¼å¼
                notes TEXT,
                created_at TEXT
            )
        """)
        
        conn.commit()
        conn.close()
        logger.info(f"ETFå›æµ‹æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {self.db_path}")
    
    def record_predictions(self, predictions: pd.DataFrame, predict_date: str = None):
        """
        è®°å½•ETFæ¯æ—¥é¢„æµ‹ç»“æœ
        """
        if predictions.empty:
            logger.warning("ETFé¢„æµ‹ç»“æœä¸ºç©ºï¼Œè·³è¿‡è®°å½•")
            return
        
        if predict_date is None:
            predict_date = datetime.now().strftime("%Y-%m-%d")
        
        # è®¡ç®—ç›®æ ‡æ—¥æœŸï¼ˆä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ï¼‰
        target_date = self._get_next_trading_day(predict_date)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # æ’å…¥é¢„æµ‹è®°å½•
        for _, row in predictions.iterrows():
            try:
                cursor.execute("""
                    INSERT OR REPLACE INTO etf_daily_predictions 
                    (predict_date, target_date, etf_code, etf_name, 
                     predict_rank, predict_score, predict_reason, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    predict_date,
                    target_date,
                    row.get('etf_code', ''),
                    row.get('etf_name', ''),
                    row.get('rank', 0),
                    row.get('pred_score', 0),
                    row.get('prediction_reason', ''),
                    now,
                    now
                ))
            except Exception as e:
                logger.error(f"è®°å½•ETFé¢„æµ‹å¤±è´¥: {e}")
        
        # åˆ›å»ºæ¯æ—¥æ±‡æ€»è®°å½•
        cursor.execute("""
            INSERT OR REPLACE INTO etf_daily_summary 
            (predict_date, target_date, total_predictions, status, created_at)
            VALUES (?, ?, ?, 'pending', ?)
        """, (predict_date, target_date, len(predictions), now))
        
        conn.commit()
        conn.close()
        
        logger.info(f"å·²è®°å½• {len(predictions)} æ¡ETFé¢„æµ‹åˆ°å›æµ‹æ•°æ®åº“")
    
    def _get_next_trading_day(self, date_str: str) -> str:
        """è·å–ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ï¼ˆç®€å•å®ç°ï¼šè·³è¿‡å‘¨æœ«ï¼‰"""
        date = datetime.strptime(date_str, "%Y-%m-%d")
        next_day = date + timedelta(days=1)
        
        # è·³è¿‡å‘¨æœ«
        while next_day.weekday() >= 5:
            next_day += timedelta(days=1)
        
        return next_day.strftime("%Y-%m-%d")
    
    def validate_predictions(self, target_date: str, actual_data: pd.DataFrame):
        """
        éªŒè¯ETFé¢„æµ‹ç»“æœ
        
        Args:
            target_date: ç›®æ ‡æ—¥æœŸ
            actual_data: å®é™…æ•°æ®DataFrameï¼Œéœ€åŒ…å« etf_code, change_pct
        """
        if actual_data.empty:
            logger.warning("ETFå®é™…æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡éªŒè¯")
            return
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # è·å–è¯¥æ—¥æœŸçš„é¢„æµ‹è®°å½•
        cursor.execute("""
            SELECT id, etf_code FROM etf_daily_predictions 
            WHERE target_date = ?
        """, (target_date,))
        predictions = cursor.fetchall()
        
        if not predictions:
            logger.warning(f"æœªæ‰¾åˆ° {target_date} çš„ETFé¢„æµ‹è®°å½•")
            conn.close()
            return
        
        # è®¡ç®—å®é™…æ’å
        actual_data = actual_data.copy()
        actual_data['actual_rank'] = actual_data['change_pct'].rank(ascending=False)
        
        # æ›´æ–°æ¯æ¡é¢„æµ‹çš„å®é™…ç»“æœ
        hit_count = 0
        top5_hit_count = 0
        returns = []
        
        for pred_id, etf_code in predictions:
            actual_row = actual_data[actual_data['etf_code'] == etf_code]
            
            if actual_row.empty:
                continue
            
            actual_change = actual_row['change_pct'].values[0]
            actual_rank = actual_row['actual_rank'].values[0]
            
            # åˆ¤æ–­æ˜¯å¦å‘½ä¸­ï¼ˆæ¶¨å¹…>0ï¼‰
            is_hit = 1 if actual_change > 0 else 0
            is_top5 = 1 if actual_rank <= 5 else 0
            
            cursor.execute("""
                UPDATE etf_daily_predictions 
                SET actual_change_pct = ?, actual_rank = ?, 
                    is_hit = ?, is_top5 = ?, updated_at = ?
                WHERE id = ?
            """, (actual_change, actual_rank, is_hit, is_top5, now, pred_id))
            
            hit_count += is_hit
            top5_hit_count += is_top5
            returns.append(actual_change)
        
        # è®¡ç®—åŸºå‡†æ”¶ç›Šï¼ˆETFæ± å¹³å‡ï¼‰
        benchmark_return = actual_data['change_pct'].mean()
        
        # æ›´æ–°æ¯æ—¥æ±‡æ€»
        avg_return = np.mean(returns) if returns else 0
        max_return = np.max(returns) if returns else 0
        min_return = np.min(returns) if returns else 0
        hit_rate = hit_count / len(predictions) if predictions else 0
        top5_hit_rate = top5_hit_count / len(predictions) if predictions else 0
        excess_return = avg_return - benchmark_return
        
        # æ‰¾åˆ°å¯¹åº”çš„predict_date
        cursor.execute("""
            SELECT predict_date FROM etf_daily_predictions 
            WHERE target_date = ? LIMIT 1
        """, (target_date,))
        result = cursor.fetchone()
        predict_date = result[0] if result else None
        
        if predict_date:
            cursor.execute("""
                UPDATE etf_daily_summary 
                SET hit_count = ?, hit_rate = ?, 
                    top5_hit_count = ?, top5_hit_rate = ?,
                    avg_return = ?, max_return = ?, min_return = ?,
                    benchmark_return = ?, excess_return = ?,
                    status = 'validated', validated_at = ?
                WHERE predict_date = ?
            """, (hit_count, hit_rate, top5_hit_count, top5_hit_rate,
                  avg_return, max_return, min_return,
                  benchmark_return, excess_return, now, predict_date))
        
        conn.commit()
        conn.close()
        
        logger.info(f"å·²éªŒè¯ {target_date} ETFé¢„æµ‹: å‘½ä¸­ç‡={hit_rate:.2%}, å¹³å‡æ”¶ç›Š={avg_return:.2f}%, è¶…é¢={excess_return:.2f}%")
    
    def get_performance_report(self, days: int = 30) -> Dict:
        """
        è·å–ETFç»©æ•ˆæŠ¥å‘Š
        """
        conn = sqlite3.connect(self.db_path)
        
        # è·å–å·²éªŒè¯çš„æ±‡æ€»æ•°æ®
        query = f"""
            SELECT * FROM etf_daily_summary 
            WHERE status = 'validated'
            AND predict_date >= date('now', '-{days} days')
            ORDER BY predict_date DESC
        """
        df = pd.read_sql(query, conn)
        conn.close()
        
        if df.empty:
            return {"status": "no_data", "message": "æš‚æ— å·²éªŒè¯çš„ETFé¢„æµ‹æ•°æ®"}
        
        # è®¡ç®—ç»¼åˆæŒ‡æ ‡
        total_predictions = df['total_predictions'].sum()
        total_hits = df['hit_count'].sum()
        overall_hit_rate = total_hits / total_predictions if total_predictions > 0 else 0
        
        avg_daily_return = df['avg_return'].mean()
        total_return = df['avg_return'].sum()
        avg_excess_return = df['excess_return'].mean()
        
        # è®¡ç®—åˆ†æ’åå‘½ä¸­ç‡
        total_top5_hits = df['top5_hit_count'].sum()
        top5_hit_rate = total_top5_hits / total_predictions if total_predictions > 0 else 0
        
        # è®¡ç®—èƒœç‡ï¼ˆæ—¥æ”¶ç›Š>0çš„å¤©æ•°ï¼‰
        win_days = (df['avg_return'] > 0).sum()
        win_rate = win_days / len(df) if len(df) > 0 else 0
        
        # è®¡ç®—æœ€å¤§å›æ’¤
        cumulative = df['avg_return'].cumsum()
        max_drawdown = (cumulative.cummax() - cumulative).max()
        
        # è®¡ç®—å¤æ™®æ¯”ç‡ï¼ˆå‡è®¾æ— é£é™©æ”¶ç›Šç‡ä¸º3%å¹´åŒ–ï¼‰
        daily_std = df['avg_return'].std()
        if daily_std > 0:
            sharpe_ratio = (avg_daily_return - 0.03/252) / daily_std * np.sqrt(252)
        else:
            sharpe_ratio = 0
        
        return {
            "status": "success",
            "period": f"{df['predict_date'].min()} ~ {df['predict_date'].max()}",
            "total_days": len(df),
            "total_predictions": total_predictions,
            "total_hits": total_hits,
            "overall_hit_rate": overall_hit_rate,
            "top5_hit_rate": top5_hit_rate,
            "avg_daily_return": avg_daily_return,
            "total_return": total_return,
            "avg_excess_return": avg_excess_return,
            "win_rate": win_rate,
            "max_drawdown": max_drawdown,
            "sharpe_ratio": sharpe_ratio,
        }
    
    def get_prediction_history(self, days: int = 7) -> pd.DataFrame:
        """è·å–è¿‘æœŸETFé¢„æµ‹å†å²"""
        conn = sqlite3.connect(self.db_path)
        
        query = f"""
            SELECT predict_date, etf_code, etf_name, predict_rank, 
                   predict_score, actual_change_pct, actual_rank, is_hit
            FROM etf_daily_predictions 
            WHERE predict_date >= date('now', '-{days} days')
            ORDER BY predict_date DESC, predict_rank
        """
        
        df = pd.read_sql(query, conn)
        conn.close()
        
        return df
    
    def export_report(self, days: int = 30) -> str:
        """å¯¼å‡ºETFå›æµ‹æŠ¥å‘Š"""
        report = self.get_performance_report(days)
        history = self.get_prediction_history(days)
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        lines = [
            "# ğŸ“Š ETFé¢„æµ‹å›æµ‹æŠ¥å‘Š",
            "",
            f"**ç»Ÿè®¡å‘¨æœŸ**: {report.get('period', 'N/A')}",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "---",
            "",
            "## ğŸ“ˆ ç»¼åˆç»©æ•ˆæŒ‡æ ‡",
            "",
            f"| æŒ‡æ ‡ | æ•°å€¼ |",
            f"|------|------|",
            f"| æ€»äº¤æ˜“å¤©æ•° | {report.get('total_days', 0)} |",
            f"| æ€»é¢„æµ‹æ¬¡æ•° | {report.get('total_predictions', 0)} |",
            f"| æ€»å‘½ä¸­æ¬¡æ•° | {report.get('total_hits', 0)} |",
            f"| æ•´ä½“å‘½ä¸­ç‡ | {report.get('overall_hit_rate', 0):.2%} |",
            f"| Top5å‘½ä¸­ç‡ | {report.get('top5_hit_rate', 0):.2%} |",
            f"| å¹³å‡æ—¥æ”¶ç›Š | {report.get('avg_daily_return', 0):.2f}% |",
            f"| ç´¯è®¡æ”¶ç›Š | {report.get('total_return', 0):.2f}% |",
            f"| å¹³å‡è¶…é¢æ”¶ç›Š | {report.get('avg_excess_return', 0):.2f}% |",
            f"| èƒœç‡ | {report.get('win_rate', 0):.2%} |",
            f"| æœ€å¤§å›æ’¤ | {report.get('max_drawdown', 0):.2f}% |",
            f"| å¤æ™®æ¯”ç‡ | {report.get('sharpe_ratio', 0):.2f} |",
            "",
        ]
        
        if not history.empty:
            lines.extend([
                "---",
                "",
                "## ğŸ“‹ è¿‘æœŸé¢„æµ‹æ˜ç»†",
                "",
                "| æ—¥æœŸ | ETFä»£ç  | ETFåç§° | é¢„æµ‹æ’å | å®é™…æ¶¨è·Œ | å‘½ä¸­ |",
                "|------|---------|---------|----------|----------|------|",
            ])
            
            for _, row in history.head(30).iterrows():
                hit_mark = "âœ…" if row.get('is_hit') == 1 else "âŒ"
                actual_change = row.get('actual_change_pct')
                actual_str = f"{actual_change:.2f}%" if pd.notna(actual_change) else "å¾…éªŒè¯"
                lines.append(
                    f"| {row['predict_date']} | {row['etf_code']} | {row['etf_name']} | "
                    f"{row['predict_rank']} | {actual_str} | {hit_mark} |"
                )
        
        lines.extend([
            "",
            "---",
            "",
            "*æŠ¥å‘Šç”± ETFé¢„æµ‹ç³»ç»Ÿ è‡ªåŠ¨ç”Ÿæˆ*",
        ])
        
        report_content = "\n".join(lines)
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = REPORT_DIR / f"etf_backtest_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report_content)
        
        logger.info(f"ETFå›æµ‹æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return str(report_path)
    
    def record_model_version(self, train_info: Dict):
        """è®°å½•æ¨¡å‹ç‰ˆæœ¬ä¿¡æ¯"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO etf_model_versions 
            (version_date, model_type, train_samples, valid_ndcg, valid_mse,
             train_start, train_end, features_used, params, notes, created_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            datetime.now().strftime("%Y-%m-%d"),
            train_info.get('model_type', 'LightGBM'),
            train_info.get('train_samples', 0),
            train_info.get('ndcg@5', 0),
            train_info.get('mse', 0),
            train_info.get('train_start', ''),
            train_info.get('train_end', ''),
            json.dumps(train_info.get('features', [])),
            json.dumps(train_info.get('params', {})),
            train_info.get('notes', ''),
            datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        ))
        
        conn.commit()
        conn.close()
        logger.info("ETFæ¨¡å‹ç‰ˆæœ¬ä¿¡æ¯å·²è®°å½•")
