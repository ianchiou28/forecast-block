"""
Aè‚¡æ¿å—æ¶¨åœé¢„æµ‹ç³»ç»Ÿ - å†å²æ•°æ®è·å–æ¨¡å—
è·å–2022-2025å¹´çš„å†å²æ•°æ®ç”¨äºå›æµ‹éªŒè¯
"""
import akshare as ak
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Tuple
import logging
import time
import os
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import warnings

warnings.filterwarnings('ignore')

# è·å–é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent
HISTORICAL_DATA_DIR = PROJECT_ROOT / "data" / "historical"

logger = logging.getLogger(__name__)


class HistoricalDataFetcher:
    """å†å²æ•°æ®è·å–å™¨ - ç”¨äºè·å–2022-2025å¹´å›æµ‹æ•°æ®"""
    
    def __init__(self):
        self.retry_times = 3
        self.retry_delay = 2
        HISTORICAL_DATA_DIR.mkdir(parents=True, exist_ok=True)
    
    def _retry_fetch(self, func, *args, **kwargs):
        """å¸¦é‡è¯•çš„æ•°æ®è·å–"""
        for i in range(self.retry_times):
            try:
                result = func(*args, **kwargs)
                return result
            except Exception as e:
                logger.warning(f"æ•°æ®è·å–å¤±è´¥ (å°è¯• {i+1}/{self.retry_times}): {e}")
                if i < self.retry_times - 1:
                    time.sleep(self.retry_delay * (i + 1))
        return None
    
    def get_trading_dates(self, start_date: str, end_date: str) -> List[str]:
        """
        è·å–æŒ‡å®šèŒƒå›´å†…çš„äº¤æ˜“æ—¥æœŸ
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ YYYY-MM-DD
            end_date: ç»“æŸæ—¥æœŸ YYYY-MM-DD
            
        Returns:
            äº¤æ˜“æ—¥æœŸåˆ—è¡¨ ['20220104', '20220105', ...]
        """
        logger.info(f"è·å–äº¤æ˜“æ—¥å†: {start_date} -> {end_date}")
        
        try:
            # ä½¿ç”¨ä¸Šè¯æŒ‡æ•°å†å²æ•°æ®è·å–äº¤æ˜“æ—¥
            df = ak.stock_zh_index_daily(symbol="sh000001")
            df['date'] = pd.to_datetime(df['date'])
            
            start = pd.to_datetime(start_date)
            end = pd.to_datetime(end_date)
            
            trading_dates = df[(df['date'] >= start) & (df['date'] <= end)]['date']
            trading_dates = [d.strftime('%Y%m%d') for d in trading_dates]
            
            logger.info(f"è·å–åˆ° {len(trading_dates)} ä¸ªäº¤æ˜“æ—¥")
            return trading_dates
        except Exception as e:
            logger.error(f"è·å–äº¤æ˜“æ—¥å†å¤±è´¥: {e}")
            return []
    
    def fetch_limit_up_history(self, date: str) -> Optional[pd.DataFrame]:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„æ¶¨åœæ± æ•°æ®
        
        Args:
            date: æ—¥æœŸ YYYYMMDDæ ¼å¼
            
        Returns:
            æ¶¨åœæ± DataFrame
        """
        try:
            df = ak.stock_zt_pool_em(date=date)
            
            if df is not None and not df.empty:
                df = df.rename(columns={
                    "åºå·": "rank",
                    "ä»£ç ": "stock_code",
                    "åç§°": "stock_name",
                    "æ¶¨è·Œå¹…": "change_pct",
                    "æœ€æ–°ä»·": "close_price",
                    "æˆäº¤é¢": "turnover",
                    "æµé€šå¸‚å€¼": "float_market_cap",
                    "æ€»å¸‚å€¼": "total_market_cap",
                    "æ¢æ‰‹ç‡": "turnover_rate",
                    "å°æ¿èµ„é‡‘": "seal_amount",
                    "é¦–æ¬¡å°æ¿æ—¶é—´": "first_seal_time",
                    "æœ€åå°æ¿æ—¶é—´": "last_seal_time",
                    "ç‚¸æ¿æ¬¡æ•°": "open_count",
                    "æ¶¨åœç»Ÿè®¡": "limit_up_stats",
                    "è¿æ¿æ•°": "continuous_limit_up",
                    "æ‰€å±è¡Œä¸š": "industry",
                })
                df["date"] = date
                return df
        except Exception as e:
            logger.debug(f"è·å– {date} æ¶¨åœæ± å¤±è´¥: {e}")
        return None
    
    def fetch_concept_board_list(self) -> List[str]:
        """è·å–æ‰€æœ‰æ¦‚å¿µæ¿å—åˆ—è¡¨"""
        try:
            df = ak.stock_board_concept_name_em()
            if df is not None:
                return df['æ¿å—åç§°'].tolist()
        except Exception as e:
            logger.error(f"è·å–æ¦‚å¿µæ¿å—åˆ—è¡¨å¤±è´¥: {e}")
        return []
    
    def fetch_concept_history(self, concept_name: str, 
                               start_date: str = None, 
                               end_date: str = None) -> Optional[pd.DataFrame]:
        """
        è·å–å•ä¸ªæ¦‚å¿µæ¿å—çš„å†å²è¡Œæƒ…
        
        Args:
            concept_name: æ¦‚å¿µæ¿å—åç§°
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            å†å²è¡Œæƒ…DataFrame
        """
        try:
            df = ak.stock_board_concept_hist_em(
                symbol=concept_name,
                period="daily",
                start_date=start_date,
                end_date=end_date,
                adjust=""
            )
            
            if df is not None and not df.empty:
                df = df.rename(columns={
                    "æ—¥æœŸ": "date",
                    "å¼€ç›˜": "open",
                    "æ”¶ç›˜": "close",
                    "æœ€é«˜": "high",
                    "æœ€ä½": "low",
                    "æˆäº¤é‡": "volume",
                    "æˆäº¤é¢": "turnover",
                    "æŒ¯å¹…": "amplitude",
                    "æ¶¨è·Œå¹…": "change_pct",
                    "æ¶¨è·Œé¢": "change_amount",
                    "æ¢æ‰‹ç‡": "turnover_rate",
                })
                df["sector_name"] = concept_name
                df["sector_type"] = "concept"
                return df
        except Exception as e:
            logger.debug(f"è·å–æ¦‚å¿µ {concept_name} å†å²è¡Œæƒ…å¤±è´¥: {e}")
        return None
    
    def fetch_industry_board_list(self) -> List[str]:
        """è·å–æ‰€æœ‰è¡Œä¸šæ¿å—åˆ—è¡¨"""
        try:
            df = ak.stock_board_industry_name_em()
            if df is not None:
                return df['æ¿å—åç§°'].tolist()
        except Exception as e:
            logger.error(f"è·å–è¡Œä¸šæ¿å—åˆ—è¡¨å¤±è´¥: {e}")
        return []
    
    def fetch_industry_history(self, industry_name: str,
                                start_date: str = None,
                                end_date: str = None) -> Optional[pd.DataFrame]:
        """
        è·å–å•ä¸ªè¡Œä¸šæ¿å—çš„å†å²è¡Œæƒ…
        """
        try:
            df = ak.stock_board_industry_hist_em(
                symbol=industry_name,
                period="daily",
                start_date=start_date,
                end_date=end_date,
                adjust=""
            )
            
            if df is not None and not df.empty:
                df = df.rename(columns={
                    "æ—¥æœŸ": "date",
                    "å¼€ç›˜": "open",
                    "æ”¶ç›˜": "close",
                    "æœ€é«˜": "high",
                    "æœ€ä½": "low",
                    "æˆäº¤é‡": "volume",
                    "æˆäº¤é¢": "turnover",
                    "æŒ¯å¹…": "amplitude",
                    "æ¶¨è·Œå¹…": "change_pct",
                    "æ¶¨è·Œé¢": "change_amount",
                    "æ¢æ‰‹ç‡": "turnover_rate",
                })
                df["sector_name"] = industry_name
                df["sector_type"] = "industry"
                return df
        except Exception as e:
            logger.debug(f"è·å–è¡Œä¸š {industry_name} å†å²è¡Œæƒ…å¤±è´¥: {e}")
        return None
    
    def fetch_all_sector_history(self, start_date: str, end_date: str,
                                  sector_type: str = "both") -> pd.DataFrame:
        """
        è·å–æ‰€æœ‰æ¿å—çš„å†å²è¡Œæƒ…æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ YYYYMMDD
            end_date: ç»“æŸæ—¥æœŸ YYYYMMDD
            sector_type: "concept", "industry", or "both"
            
        Returns:
            åˆå¹¶åçš„å†å²è¡Œæƒ…DataFrame
        """
        all_data = []
        
        # è·å–æ¦‚å¿µæ¿å—
        if sector_type in ["concept", "both"]:
            concepts = self.fetch_concept_board_list()
            logger.info(f"å¼€å§‹è·å– {len(concepts)} ä¸ªæ¦‚å¿µæ¿å—å†å²æ•°æ®...")
            
            for i, concept in enumerate(concepts):
                if i % 20 == 0:
                    logger.info(f"æ¦‚å¿µæ¿å—è¿›åº¦: {i}/{len(concepts)}")
                
                df = self._retry_fetch(
                    self.fetch_concept_history, 
                    concept, start_date, end_date
                )
                if df is not None and not df.empty:
                    all_data.append(df)
                time.sleep(0.3)  # é¿å…è¯·æ±‚è¿‡å¿«
        
        # è·å–è¡Œä¸šæ¿å—
        if sector_type in ["industry", "both"]:
            industries = self.fetch_industry_board_list()
            logger.info(f"å¼€å§‹è·å– {len(industries)} ä¸ªè¡Œä¸šæ¿å—å†å²æ•°æ®...")
            
            for i, industry in enumerate(industries):
                if i % 20 == 0:
                    logger.info(f"è¡Œä¸šæ¿å—è¿›åº¦: {i}/{len(industries)}")
                
                df = self._retry_fetch(
                    self.fetch_industry_history,
                    industry, start_date, end_date
                )
                if df is not None and not df.empty:
                    all_data.append(df)
                time.sleep(0.3)
        
        if all_data:
            result = pd.concat(all_data, ignore_index=True)
            logger.info(f"å…±è·å– {len(result)} æ¡æ¿å—å†å²è¡Œæƒ…æ•°æ®")
            return result
        
        return pd.DataFrame()
    
    def fetch_all_limit_up_history(self, start_date: str, end_date: str) -> pd.DataFrame:
        """
        è·å–æ—¥æœŸèŒƒå›´å†…æ‰€æœ‰æ¶¨åœæ± æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ YYYY-MM-DD
            end_date: ç»“æŸæ—¥æœŸ YYYY-MM-DD
            
        Returns:
            åˆå¹¶åçš„æ¶¨åœæ± DataFrame
        """
        trading_dates = self.get_trading_dates(start_date, end_date)
        
        all_data = []
        logger.info(f"å¼€å§‹è·å– {len(trading_dates)} ä¸ªäº¤æ˜“æ—¥çš„æ¶¨åœæ± æ•°æ®...")
        
        for i, date in enumerate(trading_dates):
            if i % 50 == 0:
                logger.info(f"æ¶¨åœæ± è¿›åº¦: {i}/{len(trading_dates)}")
            
            df = self._retry_fetch(self.fetch_limit_up_history, date)
            if df is not None and not df.empty:
                all_data.append(df)
            time.sleep(0.2)
        
        if all_data:
            result = pd.concat(all_data, ignore_index=True)
            logger.info(f"å…±è·å– {len(result)} æ¡æ¶¨åœæ± æ•°æ®")
            return result
        
        return pd.DataFrame()
    
    def aggregate_limit_up_by_sector(self, df_limit_up: pd.DataFrame) -> pd.DataFrame:
        """
        æŒ‰æ¿å—å’Œæ—¥æœŸèšåˆæ¶¨åœæ•°æ®
        
        Returns:
            æ¯æ—¥æ¯æ¿å—çš„æ¶¨åœç»Ÿè®¡
        """
        if df_limit_up is None or df_limit_up.empty:
            return pd.DataFrame()
        
        # æŒ‰æ—¥æœŸå’Œè¡Œä¸šèšåˆ
        agg_result = df_limit_up.groupby(["date", "industry"]).agg({
            "stock_code": "count",           # æ¶¨åœå®¶æ•°
            "turnover": "sum",               # æ€»æˆäº¤é¢
            "seal_amount": "sum",            # æ€»å°æ¿èµ„é‡‘
            "continuous_limit_up": "max",    # æœ€å¤§è¿æ¿æ•°
        }).reset_index()
        
        agg_result.columns = [
            "date", "sector_name", "limit_up_count", "total_turnover",
            "total_seal_amount", "max_continuous_limit_up"
        ]
        
        return agg_result
    
    def save_historical_data(self, sector_history: pd.DataFrame,
                              limit_up_history: pd.DataFrame,
                              start_date: str, end_date: str):
        """
        ä¿å­˜å†å²æ•°æ®åˆ°æœ¬åœ°
        """
        prefix = f"{start_date}_{end_date}"
        
        if not sector_history.empty:
            path = HISTORICAL_DATA_DIR / f"sector_history_{prefix}.parquet"
            sector_history.to_parquet(path, index=False)
            logger.info(f"æ¿å—å†å²æ•°æ®å·²ä¿å­˜: {path}")
        
        if not limit_up_history.empty:
            path = HISTORICAL_DATA_DIR / f"limit_up_history_{prefix}.parquet"
            limit_up_history.to_parquet(path, index=False)
            logger.info(f"æ¶¨åœæ± å†å²æ•°æ®å·²ä¿å­˜: {path}")
    
    def load_historical_data(self, start_date: str = None, end_date: str = None) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        åŠ è½½æœ¬åœ°å†å²æ•°æ®
        
        Returns:
            (sector_history, limit_up_history)
        """
        sector_files = list(HISTORICAL_DATA_DIR.glob("sector_history_*.parquet"))
        limit_up_files = list(HISTORICAL_DATA_DIR.glob("limit_up_history_*.parquet"))
        
        sector_data = []
        for f in sector_files:
            df = pd.read_parquet(f)
            sector_data.append(df)
        
        limit_up_data = []
        for f in limit_up_files:
            df = pd.read_parquet(f)
            limit_up_data.append(df)
        
        sector_history = pd.concat(sector_data, ignore_index=True) if sector_data else pd.DataFrame()
        limit_up_history = pd.concat(limit_up_data, ignore_index=True) if limit_up_data else pd.DataFrame()
        
        # æŒ‰æ—¥æœŸè¿‡æ»¤
        if start_date and not sector_history.empty:
            sector_history = sector_history[sector_history['date'] >= start_date]
        if end_date and not sector_history.empty:
            sector_history = sector_history[sector_history['date'] <= end_date]
        
        if start_date and not limit_up_history.empty:
            limit_up_history = limit_up_history[limit_up_history['date'] >= start_date.replace('-', '')]
        if end_date and not limit_up_history.empty:
            limit_up_history = limit_up_history[limit_up_history['date'] <= end_date.replace('-', '')]
        
        logger.info(f"åŠ è½½æ¿å—æ•°æ®: {len(sector_history)} æ¡, æ¶¨åœæ•°æ®: {len(limit_up_history)} æ¡")
        return sector_history, limit_up_history


def download_historical_data(start_year: int = 2022, end_year: int = 2025):
    """
    ä¸‹è½½æŒ‡å®šå¹´ä»½èŒƒå›´çš„å†å²æ•°æ®
    
    Usage:
        python -m backtest.historical_data
    """
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s"
    )
    
    fetcher = HistoricalDataFetcher()
    
    start_date = f"{start_year}0101"
    end_date = f"{end_year}1231"
    
    print(f"\n{'='*60}")
    print(f"å¼€å§‹ä¸‹è½½å†å²æ•°æ®: {start_year} - {end_year}")
    print(f"{'='*60}\n")
    
    # 1. è·å–æ¿å—å†å²è¡Œæƒ…
    print("ğŸ“Š æ­¥éª¤1: è·å–æ¿å—å†å²è¡Œæƒ…...")
    sector_history = fetcher.fetch_all_sector_history(start_date, end_date)
    print(f"   âœ“ è·å–åˆ° {len(sector_history)} æ¡æ¿å—è¡Œæƒ…æ•°æ®\n")
    
    # 2. è·å–æ¶¨åœæ± å†å²
    print("ğŸ”¥ æ­¥éª¤2: è·å–æ¶¨åœæ± å†å²æ•°æ®...")
    limit_up_history = fetcher.fetch_all_limit_up_history(
        f"{start_year}-01-01", f"{end_year}-12-31"
    )
    print(f"   âœ“ è·å–åˆ° {len(limit_up_history)} æ¡æ¶¨åœæ± æ•°æ®\n")
    
    # 3. ä¿å­˜æ•°æ®
    print("ğŸ’¾ æ­¥éª¤3: ä¿å­˜æ•°æ®...")
    fetcher.save_historical_data(
        sector_history, limit_up_history, 
        str(start_year), str(end_year)
    )
    
    print(f"\n{'='*60}")
    print("âœ… å†å²æ•°æ®ä¸‹è½½å®Œæˆ!")
    print(f"{'='*60}")
    
    # æ˜¾ç¤ºæ•°æ®æ‘˜è¦
    if not sector_history.empty:
        print(f"\nğŸ“ˆ æ¿å—è¡Œæƒ…æ•°æ®æ‘˜è¦:")
        print(f"   - æ—¥æœŸèŒƒå›´: {sector_history['date'].min()} ~ {sector_history['date'].max()}")
        print(f"   - æ¿å—æ•°é‡: {sector_history['sector_name'].nunique()}")
        print(f"   - æ•°æ®æ¡æ•°: {len(sector_history)}")
    
    if not limit_up_history.empty:
        print(f"\nğŸ”¥ æ¶¨åœæ± æ•°æ®æ‘˜è¦:")
        print(f"   - æ—¥æœŸèŒƒå›´: {limit_up_history['date'].min()} ~ {limit_up_history['date'].max()}")
        print(f"   - æ¶¨åœè‚¡ç¥¨æ•°: {limit_up_history['stock_code'].nunique()}")
        print(f"   - æ•°æ®æ¡æ•°: {len(limit_up_history)}")


if __name__ == "__main__":
    download_historical_data(2022, 2025)
