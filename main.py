"""
Aè‚¡æ¿å—æ¶¨åœé¢„æµ‹ç³»ç»Ÿ - ä¸»å…¥å£
æ¯æ—¥æ—©ä¸Š8ç‚¹é¢„æµ‹å½“æ—¥æ¶¨åœæ¿å—
"""
import sys
import os
import logging
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from config.settings import LOG_DIR, DATA_CONFIG
from data.data_fetcher import SectorDataFetcher
from data.data_processor import SectorDataProcessor, FeatureEngineer
from data.etf_data_fetcher import ETFDataFetcher
from data.etf_data_processor import ETFDataProcessor, ETFFeatureEngineer
from models.predictor import SectorPredictModel, RollingTrainer
from models.etf_predictor import ETFPredictModel, ETFRollingTrainer
from utils.report_generator import ReportGenerator, NotificationSender
from scheduler.task_scheduler import TaskScheduler, is_trading_day
from backtest.database import BacktestDatabase, BacktestAnalyzer
from backtest.etf_database import ETFBacktestDatabase
from backtest.etf_backtest_engine import (
    ETFHistoricalDataFetcher, 
    ETFFeatureEngineer as ETFBacktestFeatureEngineer,
    ETFRollingBacktestEngine
)

# é…ç½®æ—¥å¿—
def setup_logging():
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    log_file = LOG_DIR / f"system_{datetime.now().strftime('%Y%m%d')}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler(log_file, encoding="utf-8"),
            logging.StreamHandler()
        ]
    )

logger = logging.getLogger(__name__)


class SectorPredictSystem:
    """æ¿å—æ¶¨åœé¢„æµ‹ç³»ç»Ÿ"""
    
    def __init__(self):
        self.fetcher = SectorDataFetcher()
        self.processor = SectorDataProcessor()
        self.feature_engineer = FeatureEngineer()
        self.model = SectorPredictModel()
        self.report_generator = ReportGenerator()
        self.notifier = NotificationSender()
        self.scheduler = TaskScheduler()
        self.backtest_db = BacktestDatabase()  # å›æµ‹æ•°æ®åº“
        
        self.last_train_date = None
        self.model_info = {}
    
    def fetch_daily_data(self):
        """
        ä»»åŠ¡1: è·å–æ¯æ—¥æ•°æ®ï¼ˆæ”¶ç›˜åæ‰§è¡Œï¼‰
        """
        logger.info("=" * 50)
        logger.info("å¼€å§‹è·å–æ¯æ—¥æ•°æ®...")
        
        # è·å–æ‰€æœ‰æ•°æ®
        data = self.fetcher.fetch_all_daily_data()
        
        # ä¿å­˜åŸå§‹æ•°æ®
        self.fetcher.save_daily_data(data)
        
        # å¤„ç†æ•°æ®
        df_processed = self.processor.process_daily_data(data)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        self.processor.save_to_database(df_processed)
        
        # è‡ªåŠ¨éªŒè¯æ˜¨æ—¥é¢„æµ‹
        self.backtest_db.auto_validate_yesterday(self.processor)
        
        logger.info("æ¯æ—¥æ•°æ®è·å–å®Œæˆ")
        return df_processed
    
    def train_model(self, force: bool = False):
        """
        ä»»åŠ¡2: è®­ç»ƒ/æ›´æ–°æ¨¡å‹
        
        Args:
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°è®­ç»ƒ
        """
        logger.info("=" * 50)
        logger.info("æ£€æŸ¥æ¨¡å‹è®­ç»ƒçŠ¶æ€...")
        
        trainer = RollingTrainer(self.model)
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦é‡æ–°è®­ç»ƒ
        if not force and not trainer.should_retrain(self.last_train_date):
            logger.info("æ¨¡å‹æ— éœ€é‡æ–°è®­ç»ƒ")
            return
        
        # åŠ è½½å†å²æ•°æ®
        df = self.processor.load_history_data(days=DATA_CONFIG["history_days"])
        
        if df.empty:
            logger.warning("å†å²æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
            return
        
        # è®¡ç®—ç‰¹å¾
        df_features = self.feature_engineer.compute_features(df)
        
        if df_features.empty:
            logger.warning("ç‰¹å¾æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡è®­ç»ƒï¼ˆéœ€è¦è‡³å°‘5å¤©æ•°æ®ç§¯ç´¯ï¼‰")
            return
        
        # æ»šåŠ¨è®­ç»ƒ
        self.model_info = trainer.rolling_train(
            df_features,
            train_window_months=DATA_CONFIG["train_window_months"]
        )
        
        if self.model_info.get("status") != "skipped":
            self.last_train_date = datetime.now().strftime("%Y-%m-%d")
        
        logger.info("æ¨¡å‹è®­ç»ƒå®Œæˆ")
    
    def predict_today(self) -> dict:
        """
        ä»»åŠ¡3: ç”Ÿæˆä»Šæ—¥é¢„æµ‹ï¼ˆæ—©ä¸Š8ç‚¹æ‰§è¡Œï¼‰
        
        Returns:
            é¢„æµ‹ç»“æœå­—å…¸
        """
        logger.info("=" * 50)
        logger.info("å¼€å§‹ç”Ÿæˆä»Šæ—¥é¢„æµ‹...")
        
        # æ£€æŸ¥æ˜¯å¦äº¤æ˜“æ—¥
        if not is_trading_day():
            logger.info("ä»Šæ—¥éäº¤æ˜“æ—¥ï¼Œè·³è¿‡é¢„æµ‹")
            return {"status": "skipped", "reason": "éäº¤æ˜“æ—¥"}
        
        # åŠ è½½æœ€æ–°æ•°æ®ï¼ˆä½¿ç”¨æ˜¨æ—¥æ”¶ç›˜æ•°æ®ï¼‰
        df = self.processor.load_history_data(days=DATA_CONFIG["history_days"])
        
        if df.empty:
            logger.warning("æ— å¯ç”¨æ•°æ®ï¼Œæ— æ³•é¢„æµ‹")
            return {"status": "error", "reason": "æ•°æ®ä¸è¶³"}
        
        # è®¡ç®—ç‰¹å¾
        df_features = self.feature_engineer.compute_features(df)
        
        if df_features.empty:
            logger.warning("ç‰¹å¾æ•°æ®ä¸ºç©ºï¼Œä½¿ç”¨ç®€å•æ’åé¢„æµ‹")
            # ä½¿ç”¨ç®€å•çš„èµ„é‡‘æµæ’åä½œä¸ºé¢„æµ‹
            df_latest = df[df["date"] == df["date"].max()].copy()
            df_latest["pred_score"] = df_latest["main_net_inflow"].rank(pct=True)
            df_latest["prediction_reason"] = "åŸºäºèµ„é‡‘å‡€æµå…¥æ’åï¼ˆæ¨¡å‹è®­ç»ƒä¸­ï¼‰"
            df_latest = df_latest.sort_values("pred_score", ascending=False)
            df_latest["rank"] = range(1, len(df_latest) + 1)
            predictions = df_latest.head(5)
        else:
            # è·å–æœ€æ–°ä¸€å¤©çš„æ•°æ®ç”¨äºé¢„æµ‹
            latest_date = df_features["date"].max()
            df_latest = df_features[df_features["date"] == latest_date]
            
            logger.info(f"ä½¿ç”¨ {latest_date} æ•°æ®è¿›è¡Œé¢„æµ‹")
            
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
            if self.model.model is None:
                self.model.load_model()
            
            if self.model.model is None:
                logger.warning("æ¨¡å‹æœªè®­ç»ƒï¼Œä½¿ç”¨ç®€å•èµ„é‡‘æµæ’å")
                df_latest = df_latest.copy()
                df_latest["pred_score"] = df_latest["main_net_inflow"].rank(pct=True)
                df_latest["prediction_reason"] = "åŸºäºèµ„é‡‘å‡€æµå…¥æ’åï¼ˆæ¨¡å‹è®­ç»ƒä¸­ï¼‰"
                df_latest = df_latest.sort_values("pred_score", ascending=False)
                df_latest["rank"] = range(1, len(df_latest) + 1)
                predictions = df_latest.head(5)
            else:
                # æ‰§è¡Œæ¨¡å‹é¢„æµ‹
                predictions = self.model.predict(df_latest, top_k=5)
        
        if predictions.empty:
            logger.warning("é¢„æµ‹ç»“æœä¸ºç©º")
            return {"status": "error", "reason": "é¢„æµ‹å¤±è´¥"}
        
        # è®°å½•é¢„æµ‹åˆ°å›æµ‹æ•°æ®åº“
        self.backtest_db.record_predictions(predictions)
        logger.info("é¢„æµ‹å·²è®°å½•åˆ°å›æµ‹æ•°æ®åº“")
        
        # ç”ŸæˆæŠ¥å‘Š
        report_path = self.report_generator.generate_daily_report(
            predictions, self.model_info
        )
        
        # ç”ŸæˆHTMLæŠ¥å‘Š
        html_path = self.report_generator.generate_html_report(predictions)
        
        # ç”Ÿæˆæ–‡æœ¬æ‘˜è¦
        summary = self.report_generator.generate_text_summary(predictions)
        
        # å‘é€é€šçŸ¥
        self.notifier.send_all(summary)
        
        # æ‰“å°é¢„æµ‹ç»“æœ
        print("\n" + "=" * 60)
        print(summary)
        print("=" * 60 + "\n")
        
        return {
            "status": "success",
            "predictions": predictions.to_dict(orient="records"),
            "report_path": report_path,
            "html_path": html_path,
        }
    
    def run_full_pipeline(self):
        """è¿è¡Œå®Œæ•´æµç¨‹ï¼ˆç”¨äºæµ‹è¯•æˆ–æ‰‹åŠ¨æ‰§è¡Œï¼‰"""
        logger.info("è¿è¡Œå®Œæ•´é¢„æµ‹æµç¨‹...")
        
        # 1. è·å–æ•°æ®
        self.fetch_daily_data()
        
        # 2. è®­ç»ƒæ¨¡å‹
        self.train_model()
        
        # 3. é¢„æµ‹
        result = self.predict_today()
        
        return result
    
    def start_scheduler(self):
        """å¯åŠ¨å®šæ—¶è°ƒåº¦"""
        logger.info("é…ç½®å®šæ—¶ä»»åŠ¡...")
        
        # æ—©ä¸Š8ç‚¹: æ‰§è¡Œé¢„æµ‹
        self.scheduler.add_daily_task(
            DATA_CONFIG["predict_time"],
            self.predict_today,
            "æ—©ç›˜æ¶¨åœé¢„æµ‹"
        )
        
        # ä¸‹åˆ3:05: è·å–æ•°æ®
        self.scheduler.add_daily_task(
            DATA_CONFIG["fetch_time"],
            self.fetch_daily_data,
            "æ”¶ç›˜æ•°æ®æ›´æ–°"
        )
        
        # ä¸‹åˆ3:30: æ¨¡å‹æ›´æ–°æ£€æŸ¥
        self.scheduler.add_daily_task(
            "15:30",
            self.train_model,
            "æ¨¡å‹æ›´æ–°æ£€æŸ¥"
        )
        
        # å¯åŠ¨è°ƒåº¦å™¨
        self.scheduler.start()
        
        logger.info(f"è°ƒåº¦å™¨å·²å¯åŠ¨ï¼Œä¸‹æ¬¡æ‰§è¡Œ: {self.scheduler.get_next_run_time()}")
        
        return self.scheduler


class ETFPredictSystem:
    """ETFé¢„æµ‹ç³»ç»Ÿ"""
    
    def __init__(self):
        self.fetcher = ETFDataFetcher()
        self.processor = ETFDataProcessor()
        self.feature_engineer = ETFFeatureEngineer()
        self.model = ETFPredictModel()
        self.report_generator = ReportGenerator()
        self.notifier = NotificationSender()
        
        self.last_train_date = None
        self.model_info = {}
    
    def fetch_daily_data(self):
        """è·å–æ¯æ—¥ETFæ•°æ®"""
        logger.info("=" * 50)
        logger.info("å¼€å§‹è·å–ETFæ¯æ—¥æ•°æ®...")
        
        # è·å–æ‰€æœ‰ETFæ•°æ®
        data = self.fetcher.fetch_all_daily_data()
        
        # ä¿å­˜åŸå§‹æ•°æ®
        self.fetcher.save_daily_data(data)
        
        # å¤„ç†æ•°æ®
        df_processed = self.processor.process_daily_data(data)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        self.processor.save_to_database(df_processed)
        
        logger.info("ETFæ¯æ—¥æ•°æ®è·å–å®Œæˆ")
        return df_processed
    
    def fetch_history_data(self, days: int = 60):
        """è·å–ETFå†å²æ•°æ®ï¼ˆç”¨äºé¦–æ¬¡è®­ç»ƒï¼‰"""
        logger.info("=" * 50)
        logger.info(f"å¼€å§‹è·å–ETFå†å²æ•°æ® (è¿‘{days}å¤©)...")
        
        # è·å–å†å²æ•°æ®
        df_history = self.fetcher.fetch_all_etf_history(days=days)
        
        if df_history.empty:
            logger.warning("ETFå†å²æ•°æ®è·å–å¤±è´¥")
            return pd.DataFrame()
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        conn = __import__('sqlite3').connect(self.processor.db_path)
        
        for _, row in df_history.iterrows():
            try:
                conn.execute("""
                    INSERT OR REPLACE INTO daily_etf_data 
                    (date, etf_code, etf_name, open, high, low, close, 
                     volume, turnover, change_pct, turnover_rate, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    str(row.get("date", ""))[:10],
                    row.get("etf_code"),
                    row.get("etf_name"),
                    row.get("open"),
                    row.get("high"),
                    row.get("low"),
                    row.get("close"),
                    row.get("volume"),
                    row.get("turnover"),
                    row.get("change_pct"),
                    row.get("turnover_rate"),
                    datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                ))
            except Exception as e:
                pass
        
        conn.commit()
        conn.close()
        
        logger.info(f"ETFå†å²æ•°æ®è·å–å®Œæˆï¼Œå…± {len(df_history)} æ¡è®°å½•")
        return df_history
    
    def train_model(self, force: bool = False):
        """è®­ç»ƒETFé¢„æµ‹æ¨¡å‹"""
        logger.info("=" * 50)
        logger.info("æ£€æŸ¥ETFæ¨¡å‹è®­ç»ƒçŠ¶æ€...")
        
        trainer = ETFRollingTrainer(self.model)
        
        if not force and not trainer.should_retrain(self.last_train_date):
            logger.info("ETFæ¨¡å‹æ— éœ€é‡æ–°è®­ç»ƒ")
            return
        
        # åŠ è½½å†å²æ•°æ®
        df = self.processor.load_history_data(days=DATA_CONFIG.get("history_days", 60))
        
        if df.empty:
            logger.warning("ETFå†å²æ•°æ®ä¸ºç©ºï¼Œå°è¯•è·å–å†å²æ•°æ®...")
            self.fetch_history_data(days=60)
            df = self.processor.load_history_data(days=60)
        
        if df.empty:
            logger.warning("æ— æ³•è·å–ETFå†å²æ•°æ®ï¼Œè·³è¿‡è®­ç»ƒ")
            return
        
        # è®¡ç®—ç‰¹å¾
        df_features = self.feature_engineer.compute_features(df)
        
        if df_features.empty:
            logger.warning("ETFç‰¹å¾æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡è®­ç»ƒï¼ˆéœ€è¦æ›´å¤šæ•°æ®ç§¯ç´¯ï¼‰")
            return
        
        # æ»šåŠ¨è®­ç»ƒ
        self.model_info = trainer.rolling_train(
            df_features,
            train_window_months=DATA_CONFIG.get("train_window_months", 6)
        )
        
        if self.model_info.get("status") == "success":
            self.last_train_date = datetime.now().strftime("%Y-%m-%d")
            logger.info("ETFæ¨¡å‹è®­ç»ƒå®Œæˆ")
        else:
            logger.warning(f"ETFæ¨¡å‹è®­ç»ƒå¤±è´¥: {self.model_info.get('message', 'unknown')}")
    
    def predict_today(self) -> dict:
        """ç”Ÿæˆä»Šæ—¥ETFé¢„æµ‹"""
        logger.info("=" * 50)
        logger.info("å¼€å§‹ç”Ÿæˆä»Šæ—¥ETFé¢„æµ‹...")
        
        # åŠ è½½å†å²æ•°æ®
        df = self.processor.load_history_data(days=DATA_CONFIG.get("history_days", 60))
        
        if df.empty:
            logger.warning("æ— ETFå†å²æ•°æ®ï¼Œå°è¯•è·å–...")
            self.fetch_history_data(days=60)
            df = self.processor.load_history_data(days=60)
        
        if df.empty:
            logger.warning("æ— å¯ç”¨ETFæ•°æ®")
            return {"status": "error", "reason": "æ•°æ®ä¸è¶³"}
        
        # è®¡ç®—ç‰¹å¾
        df_features = self.feature_engineer.compute_features(df)
        
        if df_features.empty:
            logger.warning("ETFç‰¹å¾æ•°æ®ä¸ºç©ºï¼Œä½¿ç”¨ç®€å•æ’åé¢„æµ‹")
            # ä½¿ç”¨ç®€å•çš„æ¶¨å¹…æ’åä½œä¸ºé¢„æµ‹
            df_latest = df[df["date"] == df["date"].max()].copy()
            if df_latest.empty:
                return {"status": "error", "reason": "æ— æœ€æ–°æ•°æ®"}
            
            # æ ¹æ®è¿‘æœŸæ¶¨è·Œå¹…å’Œæˆäº¤é‡ç»¼åˆæ’å
            df_latest["pred_score"] = df_latest["change_pct"].rank(pct=True)
            df_latest["prediction_reason"] = "åŸºäºè¿‘æœŸè¡¨ç°æ’åï¼ˆæ¨¡å‹è®­ç»ƒä¸­ï¼‰"
            df_latest = df_latest.sort_values("pred_score", ascending=False)
            df_latest["rank"] = range(1, len(df_latest) + 1)
            predictions = df_latest.head(5)
        else:
            # è·å–æœ€æ–°ä¸€å¤©çš„æ•°æ®
            latest_date = df_features["date"].max()
            df_latest = df_features[df_features["date"] == latest_date]
            
            logger.info(f"ä½¿ç”¨ {latest_date} ETFæ•°æ®è¿›è¡Œé¢„æµ‹")
            
            # æ£€æŸ¥æ¨¡å‹
            if self.model.model is None:
                self.model.load_model()
            
            if self.model.model is None:
                logger.warning("ETFæ¨¡å‹æœªè®­ç»ƒï¼Œä½¿ç”¨ç®€å•æ’å")
                df_latest = df_latest.copy()
                df_latest["pred_score"] = df_latest.get("return_5d", df_latest.get("change_pct", 0)).rank(pct=True)
                df_latest["prediction_reason"] = "åŸºäºè¿‘æœŸè¡¨ç°æ’åï¼ˆæ¨¡å‹è®­ç»ƒä¸­ï¼‰"
                df_latest = df_latest.sort_values("pred_score", ascending=False)
                df_latest["rank"] = range(1, len(df_latest) + 1)
                predictions = df_latest.head(5)
            else:
                # æ‰§è¡Œæ¨¡å‹é¢„æµ‹
                predictions = self.model.predict(df_latest, top_k=5)
        
        if predictions.empty:
            return {"status": "error", "reason": "é¢„æµ‹å¤±è´¥"}
        
        # è®°å½•é¢„æµ‹
        self._record_predictions(predictions)
        
        # ç”ŸæˆæŠ¥å‘Š
        report_path = self._generate_etf_report(predictions)
        
        # ç”Ÿæˆæ–‡æœ¬æ‘˜è¦
        summary = self._generate_etf_summary(predictions)
        
        # æ‰“å°é¢„æµ‹ç»“æœ
        print("\n" + "=" * 60)
        print(summary)
        print("=" * 60 + "\n")
        
        return {
            "status": "success",
            "predictions": predictions.to_dict(orient="records"),
            "report_path": report_path,
        }
    
    def _record_predictions(self, predictions: pd.DataFrame):
        """è®°å½•é¢„æµ‹åˆ°æ•°æ®åº“"""
        conn = __import__('sqlite3').connect(self.processor.db_path)
        
        today = datetime.now().strftime("%Y-%m-%d")
        
        for _, row in predictions.iterrows():
            conn.execute("""
                INSERT INTO etf_predictions 
                (predict_date, etf_code, etf_name, pred_score, rank, prediction_reason, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                today,
                row.get("etf_code"),
                row.get("etf_name"),
                row.get("pred_score"),
                row.get("rank"),
                row.get("prediction_reason"),
                datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            ))
        
        conn.commit()
        conn.close()
        logger.info(f"å·²è®°å½• {len(predictions)} æ¡ETFé¢„æµ‹")
    
    def _generate_etf_report(self, predictions: pd.DataFrame) -> str:
        """ç”ŸæˆETFé¢„æµ‹æŠ¥å‘Š"""
        today = datetime.now().strftime("%Y-%m-%d")
        predict_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        
        report_lines = [
            f"# ğŸ“Š ETFæ¶¨å¹…é¢„æµ‹æŠ¥å‘Š",
            f"",
            f"**é¢„æµ‹æ—¥æœŸ**: {predict_date}",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%H:%M:%S')}",
            f"",
            f"---",
            f"",
            f"## ğŸ¯ ä»Šæ—¥é¢„æµ‹ETF Top-5",
            f"",
            f"| æ’å | ETFä»£ç  | ETFåç§° | é¢„æµ‹å¾—åˆ† | é¢„æµ‹ç†ç”± |",
            f"|------|---------|---------|----------|----------|",
        ]
        
        for _, row in predictions.head(5).iterrows():
            rank = row.get("rank", "-")
            code = row.get("etf_code", "-")
            name = row.get("etf_name", "-")
            score = row.get("pred_score", 0)
            reason = row.get("prediction_reason", "-")
            report_lines.append(f"| {rank} | {code} | **{name}** | {score:.4f} | {reason} |")
        
        report_lines.extend([
            f"",
            f"---",
            f"",
            f"## âš ï¸ é£é™©æç¤º",
            f"",
            f"1. æœ¬é¢„æµ‹ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®",
            f"2. ETFæŠ•èµ„æœ‰é£é™©ï¼Œè¯·è°¨æ…å†³ç­–",
            f"",
            f"*æŠ¥å‘Šç”± ETFé¢„æµ‹ç³»ç»Ÿ è‡ªåŠ¨ç”Ÿæˆ*",
        ])
        
        report_content = "\n".join(report_lines)
        
        # ä¿å­˜æŠ¥å‘Š
        from config.settings import REPORT_DIR
        report_path = REPORT_DIR / f"etf_prediction_report_{today}.md"
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report_content)
        
        logger.info(f"ETFé¢„æµ‹æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return str(report_path)
    
    def _generate_etf_summary(self, predictions: pd.DataFrame) -> str:
        """ç”ŸæˆETFé¢„æµ‹æ‘˜è¦"""
        today = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        
        lines = [
            f"ğŸ“Š ã€ETFæ¶¨å¹…é¢„æµ‹ã€‘{today}",
            f"",
            f"ğŸ¯ ä»Šæ—¥é¢„æµ‹ETF:",
        ]
        
        for i, (_, row) in enumerate(predictions.head(5).iterrows(), 1):
            code = row.get("etf_code", "-")
            name = row.get("etf_name", "-")
            score = row.get("pred_score", 0)
            reason = row.get("prediction_reason", "")
            lines.append(f"{i}. {name}({code}) (å¾—åˆ†:{score:.2f})")
            if reason:
                lines.append(f"   â””â”€ {reason}")
        
        lines.extend([
            f"",
            f"âš ï¸ ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®",
        ])
        
        return "\n".join(lines)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Aè‚¡æ¿å—æ¶¨åœé¢„æµ‹ç³»ç»Ÿ & ETFé¢„æµ‹ç³»ç»Ÿ")
    parser.add_argument(
        "--mode", 
        choices=["predict", "train", "fetch", "full", "daemon", "backtest", "report",
                 "etf-predict", "etf-train", "etf-fetch", "etf-full", "etf-backtest", 
                 "etf-backtest-run", "etf-report", "all-predict"],
        default="predict",
        help="è¿è¡Œæ¨¡å¼: predict(æ¿å—é¢„æµ‹), train(æ¿å—è®­ç»ƒ), fetch(è·å–æ¿å—æ•°æ®), full(æ¿å—å®Œæ•´æµç¨‹), "
             "daemon(å®ˆæŠ¤è¿›ç¨‹), backtest(å›æµ‹ç»Ÿè®¡), report(ç”Ÿæˆå›æµ‹æŠ¥å‘Š), "
             "etf-predict(ETFé¢„æµ‹), etf-train(ETFè®­ç»ƒ), etf-fetch(è·å–ETFæ•°æ®), etf-full(ETFå®Œæ•´æµç¨‹), "
             "etf-backtest(ETFå›æµ‹ç»Ÿè®¡), etf-backtest-run(è¿è¡Œ3å¹´ETFæ»šåŠ¨å›æµ‹), etf-report(ETFå›æµ‹æŠ¥å‘Š), "
             "all-predict(åŒæ—¶é¢„æµ‹æ¿å—å’ŒETF)"
    )
    parser.add_argument(
        "--force-train",
        action="store_true",
        help="å¼ºåˆ¶é‡æ–°è®­ç»ƒæ¨¡å‹"
    )
    parser.add_argument(
        "--days",
        type=int,
        default=30,
        help="å›æµ‹ç»Ÿè®¡å¤©æ•° / ETFå†å²æ•°æ®å¤©æ•°"
    )
    parser.add_argument(
        "--years",
        type=int,
        default=3,
        help="ETFå†å²æ•°æ®å¹´æ•°ï¼ˆé»˜è®¤3å¹´ï¼‰"
    )
    parser.add_argument(
        "--train-months",
        type=int,
        default=24,
        help="ETFå›æµ‹è®­ç»ƒçª—å£ï¼ˆæœˆï¼‰ï¼Œé»˜è®¤24ä¸ªæœˆ"
    )
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–æ—¥å¿—
    setup_logging()
    
    logger.info("=" * 60)
    logger.info("Aè‚¡é¢„æµ‹ç³»ç»Ÿå¯åŠ¨")
    logger.info(f"è¿è¡Œæ¨¡å¼: {args.mode}")
    logger.info("=" * 60)
    
    # æ ¹æ®æ¨¡å¼é€‰æ‹©ç³»ç»Ÿ
    if args.mode.startswith("etf"):
        
        # ETFå›æµ‹ç›¸å…³å‘½ä»¤
        if args.mode == "etf-backtest-run":
            # è¿è¡Œ3å¹´ETFæ»šåŠ¨å›æµ‹
            logger.info("=" * 60)
            logger.info("ğŸ“Š å¼€å§‹ETFæ»šåŠ¨å›æµ‹ï¼ˆ3å¹´æ•°æ®ï¼‰...")
            logger.info("=" * 60)
            
            # è·å–å†å²æ•°æ®
            fetcher = ETFHistoricalDataFetcher()
            
            # å°è¯•åŠ è½½æœ¬åœ°ç¼“å­˜
            df_history = fetcher.load_history_data()
            
            if df_history.empty:
                logger.info(f"æœ¬åœ°æ— ç¼“å­˜ï¼Œè·å–{args.years}å¹´ETFå†å²æ•°æ®...")
                df_history = fetcher.fetch_all_etf_history(years=args.years)
                if not df_history.empty:
                    fetcher.save_history_data(df_history)
            else:
                logger.info(f"ä½¿ç”¨æœ¬åœ°ç¼“å­˜æ•°æ®: {len(df_history)} æ¡")
            
            if df_history.empty:
                logger.error("æ— æ³•è·å–ETFå†å²æ•°æ®!")
                return
            
            # è®¡ç®—å›æµ‹æ—¶é—´èŒƒå›´
            end_date = datetime.now().strftime("%Y-%m-%d")
            start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")  # æœ€è¿‘1å¹´å›æµ‹
            
            # è¿è¡Œæ»šåŠ¨å›æµ‹
            engine = ETFRollingBacktestEngine(
                train_window_months=args.train_months,
                step_months=1
            )
            
            results = engine.run_backtest(df_history, start_date, end_date)
            
            if not results.empty:
                print(f"\nâœ… ETFå›æµ‹å®Œæˆ! å…± {len(results)} æ¡é¢„æµ‹è®°å½•")
            else:
                print("\nâŒ ETFå›æµ‹å¤±è´¥!")
                
        elif args.mode == "etf-backtest":
            # ETFå›æµ‹ç»Ÿè®¡
            etf_backtest_db = ETFBacktestDatabase()
            report = etf_backtest_db.get_performance_report(days=args.days)
            
            print("\n" + "=" * 60)
            print("ğŸ“Š ETFå›æµ‹ç»©æ•ˆç»Ÿè®¡")
            print("=" * 60)
            
            if report.get("status") == "no_data":
                print("æš‚æ— å·²éªŒè¯çš„ETFé¢„æµ‹æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œå›æµ‹æˆ–å‡ å¤©é¢„æµ‹åå†æŸ¥çœ‹")
            else:
                print(f"ğŸ“… ç»Ÿè®¡å‘¨æœŸ: {report.get('period', 'N/A')}")
                print(f"ğŸ“ˆ æ€»äº¤æ˜“å¤©æ•°: {report.get('total_days', 0)}")
                print(f"ğŸ“ˆ æ€»é¢„æµ‹æ¬¡æ•°: {report.get('total_predictions', 0)}")
                print(f"âœ… æ€»å‘½ä¸­æ¬¡æ•°: {report.get('total_hits', 0)}")
                print(f"ğŸ¯ æ•´ä½“å‘½ä¸­ç‡: {report.get('overall_hit_rate', 0):.2%}")
                print(f"ğŸ¯ Top5å‘½ä¸­ç‡: {report.get('top5_hit_rate', 0):.2%}")
                print(f"ğŸ’° å¹³å‡æ—¥æ”¶ç›Š: {report.get('avg_daily_return', 0):.2f}%")
                print(f"ğŸ“Š ç´¯è®¡æ”¶ç›Š: {report.get('total_return', 0):.2f}%")
                print(f"ğŸ’ å¹³å‡è¶…é¢æ”¶ç›Š: {report.get('avg_excess_return', 0):.2f}%")
                print(f"ğŸ† èƒœç‡: {report.get('win_rate', 0):.2%}")
                print(f"ğŸ“‰ æœ€å¤§å›æ’¤: {report.get('max_drawdown', 0):.2f}%")
                print(f"ğŸ“Š å¤æ™®æ¯”ç‡: {report.get('sharpe_ratio', 0):.2f}")
            
            print("=" * 60)
            
        elif args.mode == "etf-report":
            # ç”ŸæˆETFå›æµ‹æŠ¥å‘Š
            etf_backtest_db = ETFBacktestDatabase()
            report_path = etf_backtest_db.export_report(days=args.days)
            print(f"\nETFå›æµ‹æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
            
            # æ˜¾ç¤ºè¿‘æœŸé¢„æµ‹
            history = etf_backtest_db.get_prediction_history(days=7)
            if not history.empty:
                print("\nğŸ“‹ è¿‘æœŸETFé¢„æµ‹è®°å½•:")
                print(history[['predict_date', 'etf_code', 'etf_name', 
                              'predict_rank', 'actual_change_pct', 'is_hit']].to_string(index=False))
        
        else:
            # ETFé¢„æµ‹ç³»ç»Ÿ
            system = ETFPredictSystem()
            
            if args.mode == "etf-predict":
                result = system.predict_today()
                print(f"\nETFé¢„æµ‹ç»“æœ: {result['status']}")
                
            elif args.mode == "etf-train":
                system.train_model(force=args.force_train)
            
            elif args.mode == "etf-fetch":
                # è·å–å†å²æ•°æ®
                system.fetch_history_data(days=args.days)
                # è·å–æœ€æ–°æ•°æ®
                system.fetch_daily_data()
                
            elif args.mode == "etf-full":
                # å®Œæ•´æµç¨‹ï¼šè·å–æ•°æ® -> è®­ç»ƒ -> é¢„æµ‹
                logger.info("æ‰§è¡ŒETFå®Œæ•´æµç¨‹...")
                system.fetch_history_data(days=args.days)
                system.train_model(force=True)
                result = system.predict_today()
                print(f"\nETFæ‰§è¡Œç»“æœ: {result['status']}")
    
    elif args.mode == "all-predict":
        # åŒæ—¶é¢„æµ‹æ¿å—å’ŒETF
        logger.info("=" * 60)
        logger.info("ğŸ“ˆ å¼€å§‹æ¿å—é¢„æµ‹...")
        logger.info("=" * 60)
        
        sector_system = SectorPredictSystem()
        sector_result = sector_system.predict_today()
        
        logger.info("=" * 60)
        logger.info("ğŸ“Š å¼€å§‹ETFé¢„æµ‹...")
        logger.info("=" * 60)
        
        etf_system = ETFPredictSystem()
        etf_result = etf_system.predict_today()
        
        print(f"\næ¿å—é¢„æµ‹ç»“æœ: {sector_result['status']}")
        print(f"ETFé¢„æµ‹ç»“æœ: {etf_result['status']}")
        
    else:
        # æ¿å—é¢„æµ‹ç³»ç»Ÿ
        system = SectorPredictSystem()
        
        if args.mode == "predict":
            result = system.predict_today()
            print(f"\né¢„æµ‹ç»“æœ: {result['status']}")
            
        elif args.mode == "train":
            system.train_model(force=args.force_train)
            
        elif args.mode == "fetch":
            system.fetch_daily_data()
            
        elif args.mode == "full":
            result = system.run_full_pipeline()
            print(f"\næ‰§è¡Œç»“æœ: {result['status']}")
            
        elif args.mode == "daemon":
            scheduler = system.start_scheduler()
            
            print("\nç³»ç»Ÿå·²è¿›å…¥å®ˆæŠ¤æ¨¡å¼ï¼ŒæŒ‰ Ctrl+C é€€å‡º")
            print(f"ä¸‹æ¬¡é¢„æµ‹æ—¶é—´: {scheduler.get_next_run_time()}")
            
            try:
                while True:
                    import time
                    time.sleep(60)
            except KeyboardInterrupt:
                logger.info("æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
                scheduler.stop()
        
        elif args.mode == "backtest":
            report = system.backtest_db.get_performance_report(days=args.days)
            
            print("\n" + "=" * 60)
            print("ğŸ“Š å›æµ‹ç»©æ•ˆç»Ÿè®¡")
            print("=" * 60)
            
            if report.get("status") == "no_data":
                print("æš‚æ— å·²éªŒè¯çš„é¢„æµ‹æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œå‡ å¤©é¢„æµ‹åå†æŸ¥çœ‹")
            else:
                print(f"ğŸ“… ç»Ÿè®¡å‘¨æœŸ: {report.get('period', 'N/A')}")
                print(f"ğŸ“ˆ æ€»é¢„æµ‹æ¬¡æ•°: {report.get('total_predictions', 0)}")
                print(f"âœ… æ€»å‘½ä¸­æ¬¡æ•°: {report.get('total_hits', 0)}")
                print(f"ğŸ¯ æ•´ä½“å‘½ä¸­ç‡: {report.get('overall_hit_rate', 0):.2%}")
                print(f"ğŸ’° å¹³å‡æ—¥æ”¶ç›Š: {report.get('avg_daily_return', 0):.2f}%")
                print(f"ğŸ“Š ç´¯è®¡æ”¶ç›Š: {report.get('total_return', 0):.2f}%")
                print(f"ğŸ’ å¹³å‡è¶…é¢æ”¶ç›Š: {report.get('avg_excess_return', 0):.2f}%")
                print(f"\nğŸ¯ åˆ†æ’åå‘½ä¸­ç‡:")
                print(f"   Top-1: {report.get('top1_hit_rate', 0):.2%}")
                print(f"   Top-3: {report.get('top3_hit_rate', 0):.2%}")
                print(f"   Top-5: {report.get('top5_hit_rate', 0):.2%}")
            
            print("=" * 60)
            
        elif args.mode == "report":
            report_path = system.backtest_db.export_report()
            print(f"\nå›æµ‹æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
            
            history = system.backtest_db.get_prediction_history(days=7)
            if not history.empty:
                print("\nğŸ“‹ è¿‘æœŸé¢„æµ‹è®°å½•:")
                print(history[['predict_date', 'sector_name', 'predict_rank', 
                              'actual_change_pct', 'is_hit']].to_string(index=False))
    
    logger.info("ç³»ç»Ÿé€€å‡º")


if __name__ == "__main__":
    main()
